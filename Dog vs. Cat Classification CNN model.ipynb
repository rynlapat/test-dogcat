{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Flask app on Image Classification of Dog/Cat Dataset implemented by Convolutional Neural Network (CNN)\n",
    "\n",
    "### Phuong T.M. Chu & Minh H. Nguyen\n",
    "This is the project that we finished after the 6th week of studying **Machine Learning**.\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img width=\"760\" height=\"400\" src=\"https://miro.medium.com/max/1838/1*oB3S5yHHhvougJkPXuc8og.gif\">\n",
    "</p>\n",
    "\n",
    "## INTRODUCTION\n",
    "### 1. Dataset\n",
    "**Dogs vs. Cats** [dataset](https://www.kaggle.com/c/dogs-vs-cats/data) provided by  Microsoft Research contains 25,000 images of dogs and cats with the labels \n",
    "* 1 = dog\n",
    "* 0 = cat \n",
    "\n",
    "### 2. Project goals\n",
    "- Building a **deep neural network** using **TensorFlow** to classify dogs and cats images **(This Jupyter Notebook is dedicated for the building model part)**. \n",
    "\n",
    "- Making a **Flask application** so user can upload their photos and receive the prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HOW IT WORK: CONVOLUTIONAL NEURAL NETWORK (CNN)\n",
    "\n",
    "> In deep learning, a [convolutional neural network](https://en.wikipedia.org/wiki/Convolutional_neural_network) (CNN, or ConvNet) is a class of deep neural networks, most commonly applied to analyzing visual imagery. (Wiki)\n",
    "\n",
    "For this project, we used **pre-trained model [MobileNetV2](https://keras.io/applications/#mobilenetv2)** from keras. MobileNetV2 is a model that was trained on a large dataset to solve a **similar problem to this project**, so it will help us to save lots of time on buiding low-level layers and focus on the application.\n",
    "\n",
    "**Note that we assumed you have knowledge about CNN architecture. If this is not the case, you can learn more about it [here](https://medium.com/@RaghavPrabhu/understanding-of-convolutional-neural-network-cnn-deep-learning-99760835f148)*  \n",
    "\n",
    "![](https://www.datascience.com/hs-fs/hubfs/CNN%202.png?width=650&name=CNN%202.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0-beta1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-24T11:23:34.786473Z",
     "start_time": "2019-08-24T11:23:23.839113Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "# Working with directory library\n",
    "from os import path, listdir\n",
    "from os.path import isdir\n",
    "\n",
    "# Image visualization\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-24T07:10:54.127599Z",
     "start_time": "2019-08-24T07:10:54.115598Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define function to load image from path, return all image paths and labels.\n",
    "\n",
    "def load_image_dataset(file_path):\n",
    "    all_image_dirs = [path.join(file_path, f) for f in listdir(file_path) if not isdir(path.join(file_path, f))]\n",
    "    all_image_labels = []\n",
    "    for f in all_image_dirs:\n",
    "        if f.split('.')[0][-3:] == 'cat':\n",
    "            all_image_labels.append(0)\n",
    "        else:\n",
    "            all_image_labels.append(1)\n",
    "    return all_image_dirs, all_image_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-24T07:10:54.868121Z",
     "start_time": "2019-08-24T07:10:54.620389Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load and save image paths and labels\n",
    "\n",
    "all_image_dirs, all_image_labels = load_image_dataset('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-24T07:18:08.218910Z",
     "start_time": "2019-08-24T07:18:08.210910Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function that take care of preprocessing image\n",
    "\n",
    "def preprocess_image(image):\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, [192, 192])\n",
    "    image /= 255.0  # normalize to [0,1] range\n",
    "    image = 2*image-1  # normalize to [-1,1] range\n",
    "    return image\n",
    "\n",
    "def load_and_preprocess_image(path):\n",
    "    image = tf.io.read_file(path)\n",
    "    return preprocess_image(image)\n",
    "\n",
    "def load_and_preprocess_from_path_label(path, label):\n",
    "    return load_and_preprocess_image(path), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data to train and test set.\n",
    "\n",
    "num_train_image = int(len(all_image_labels)*0.8//1)\n",
    "train_image_dirs, train_label = all_image_dirs[:num_train_image], all_image_labels[:num_train_image]\n",
    "test_image_dirs, test_label = all_image_dirs[num_train_image:], all_image_labels[num_train_image:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-24T07:19:35.795961Z",
     "start_time": "2019-08-24T07:19:35.697963Z"
    }
   },
   "outputs": [],
   "source": [
    "# Put the image's paths and labels of train and test set to tensorflow dataset.\n",
    "\n",
    "train_path_label = tf.data.Dataset.from_tensor_slices((train_image_dirs, train_label))\n",
    "test_path_label = tf.data.Dataset.from_tensor_slices((test_image_dirs, test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess all the images, put it in the same place with their labels.\n",
    "\n",
    "train_image_label_ds = train_path_label.map(load_and_preprocess_from_path_label)\n",
    "test_image_label_ds = test_path_label.map(load_and_preprocess_from_path_label).batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-24T07:23:48.331208Z",
     "start_time": "2019-08-24T07:23:48.324182Z"
    }
   },
   "outputs": [],
   "source": [
    "# implement batch for train set.\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "train_ds = train_image_label_ds.shuffle(buffer_size = len(all_image_labels))\n",
    "train_ds = train_ds.repeat()\n",
    "train_ds = train_ds.batch(BATCH_SIZE)\n",
    "train_ds = train_ds.prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of MobileNetV2 as pre-trained model.\n",
    "\n",
    "mobile_net = tf.keras.applications.MobileNetV2(input_shape=(192, 192, 3), include_top=False)\n",
    "mobile_net.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-23T06:21:51.725149Z",
     "start_time": "2019-08-23T06:21:51.585150Z"
    }
   },
   "outputs": [],
   "source": [
    "# Build the CNN-model\n",
    "\n",
    "cnn_model = keras.models.Sequential([\n",
    "    mobile_net,\n",
    "    keras.layers.GlobalAveragePooling2D(),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(64, activation=\"relu\"),\n",
    "    keras.layers.Dense(2, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-23T06:21:52.189154Z",
     "start_time": "2019-08-23T06:21:52.175153Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "mobilenetv2_1.00_192 (Model) (None, 6, 6, 1280)        2257984   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                81984     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 2,340,098\n",
      "Trainable params: 82,114\n",
      "Non-trainable params: 2,257,984\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile CNN-model\n",
    "\n",
    "cnn_model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-23T06:22:27.145968Z",
     "start_time": "2019-08-23T06:21:52.672156Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0825 06:36:30.727654 139834907649792 deprecation.py:323] From /home/jupyter/.local/lib/python3.5/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 946s 1s/step - loss: 0.1297 - accuracy: 0.9478 - val_loss: 0.0737 - val_accuracy: 0.9758\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f2cc4eaaef0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model with the train_ds above.\n",
    "\n",
    "steps_per_epoch=tf.math.ceil(len(all_image_dirs)/BATCH_SIZE).numpy()\n",
    "cnn_model.fit(train_ds, epochs=2, steps_per_epoch=steps_per_epoch, validation_data=test_image_label_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model for flask usage.\n",
    "\n",
    "cnn_model.save('dog_cat_M.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL PERFOMANCE SUMARY\n",
    "Our model has the accuracy of **97.79 %** for the train dataset and **97.32 %** for the test dataset. \n",
    "Then, this model is combined with the Flask Application so user can upload their images and classify easily."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
